{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Machine_Learning_foundation class notes.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "0eJJixHnCsfq",
        "2zj6oJHhCsgA"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7vuNV0LCse0",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://github.com/insaid2018/Term-1/blob/master/Images/INSAID_Full%20Logo.png?raw=true\" width=\"240\" height=\"360\" />\n",
        "# TERM - 2\n",
        "# INTRO TO MACHINE LEARNING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIVnJqbVCse4",
        "colab_type": "text"
      },
      "source": [
        "## Data Science from different perspective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeCnVDLGCse7",
        "colab_type": "text"
      },
      "source": [
        "## What is Data Science\n",
        "\n",
        "Data science is an interdisciplinary field about __scientific__ _methods_, _processes_ and _systems_ to extract __Knowledge or insights__ from data in various forms, either __structured or unstructured__.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0tbDYu0EuuM",
        "colab_type": "text"
      },
      "source": [
        "**It is a field of study that gives the ability to the computer for self-learn with the new data every time without being explicitly programmed.**\n",
        "\n",
        "**A computer algorithm/program is said to learn from performance measure P and experience E with some class of tasks T if its performance at tasks in T, as measured by P, improves with experience E.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc6lcOaUCse8",
        "colab_type": "text"
      },
      "source": [
        "  \n",
        "\n",
        "\n",
        "\n",
        "## Data Science Process\n",
        "\n",
        "The three components involved in data science are __organising__, __packaging__ and __delivering__ data.<br/>\n",
        "The 3 step OPD Data Science Process\n",
        "\n",
        "### Step 1. Organise Data.\n",
        "Organising data involves the __physical storage and format of data__ and incorporated best practices in data management.\n",
        "\n",
        "### Step 2. Package Data. \n",
        "Packaging data involves __logically manipulating__ and __joining the underlying raw data__ into a _new representation_ and package.\n",
        "\n",
        "### Step 3. Deliver Data.\n",
        "Delivering data involves ensuring that the __message__ the __data__ has is being accessed by those that need to hear it.\n",
        "\n",
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8VZxMWdCse9",
        "colab_type": "text"
      },
      "source": [
        "## Intro to Machine Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LDlvX8dCse_",
        "colab_type": "text"
      },
      "source": [
        "#### Machine learning is the idea that there are generic algorithms that can tell you something interesting about a set of data without you having to write any custom code specific to the problem. \n",
        "\n",
        "Instead of writing code, you feed data to the generic algorithm and it builds its own logic based on the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIft_T8kCsfC",
        "colab_type": "text"
      },
      "source": [
        "# Types of Machine Learning Systems\n",
        "\n",
        "There are so many different types of Machine Learning systems that it is useful to classify them in broad categories based on:\n",
        "- Whether or not they are trained with human supervision (__supervised__, __unsupervised__, __semisupervised__, and __Reinforcement Learning__)\n",
        "- Whether or not they can learn incrementally on the fly (__online versus batch learning__)\n",
        "- Whether they work by simply comparing new data points to known data points, or instead detect patterns in the training data and build a predictive model, much like scientists do (__instance-based versus model-based learning__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEBS0DNd4QTc",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/AnkitNigam1985/Data-Science/master/tmp_images/tmp1.PNG\" width=\"360\" height=\"360\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GShKxQTxCsfD",
        "colab_type": "text"
      },
      "source": [
        "## Supervised Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j19weogCsfH",
        "colab_type": "text"
      },
      "source": [
        "Supervised learning is where you have input variables (x) and an output variable (Y) and you use an algorithm to learn the mapping function from the input to the output. The __goal__ is to _approximate the mapping function so well that when you have new input data (x) that you can predict the output variables (Y) for that data_.\n",
        "\n",
        "\n",
        "\n",
        "*Supervised Learning is the first type of machine learning, in \n",
        "which labelled data used to train the algorithms. In supervised learning, \n",
        "algorithms are trained using marked data, where the input and the output are \n",
        "known. We input the data in the learning algorithm as a set of inputs, which is \n",
        "called as Features, denoted by X along with the corresponding outputs, which \n",
        "is indicated by Y, and the algorithm learns by comparing its actual production \n",
        "with correct outputs to find errors. It then modifies the model accordingly. \n",
        "\n",
        "The raw data divided into two parts. The first part is for training the algorithm, and the other region used for test the trained algorithm.*\n",
        "\n",
        "\n",
        "\n",
        "*Supervised learning uses the data patterns to predict the values of additional \n",
        "data for the labels. This method will commonly use in applications where \n",
        "historical data predict likely upcoming events. Ex: - It can anticipate when \n",
        "transactions are likely to be fraudulent or which insurance customer is \n",
        "expected to file a claim.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fg6NgD5x5Gm8",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/AnkitNigam1985/Data-Science/master/tmp_images/tmp2.PNG\" width=\"450\" height=\"450\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJEfkRvN5h2S",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/AnkitNigam1985/Data-Science/master/tmp_images/tmp3.PNG\" width=\"450\" height=\"450\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_OpFMqECsfJ",
        "colab_type": "text"
      },
      "source": [
        "## Supervised learning problems can be further grouped into regression and classification problems.\n",
        "\n",
        "#### Classification:\n",
        "A __classification problem__ is when the output variable is a __category__, such as “red” or “blue” or “disease” and “no disease”.\n",
        "#### Regression: \n",
        "A __regression problem__ is when the output variable is a __real value__, such as “rupees” or “weight”.\n",
        "\n",
        "Regression is the type of Supervised Learning in which labelled data used, and \n",
        "this data is used to make predictions in a continuous form. The output of the \n",
        "input is always ongoing, and the graph is linear. Regression is a form of \n",
        "predictive modelling technique which investigates the relationship between a \n",
        "dependent variable [Outputs] and independent variable [Inputs]. This \n",
        "technique used for forecasting the weather, time series modelling, process \n",
        "optimization. Ex: - One of the examples of the regression technique is House \n",
        "Price Prediction, where the price of the house will predict from the inputs such as No of rooms, Locality, Ease of transport, Age of house, Area of a home."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09k7yCdlCsfK",
        "colab_type": "text"
      },
      "source": [
        "#### Some popular examples of supervised machine learning algorithms are:\n",
        "\n",
        "- __Linear regression__ for _regression_ problems,\n",
        "- __Random forest__ for _classification_ and _regression_ problems,\n",
        "- __Support vector machines (SVM)__ for _classification_ problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvCVYzETCsfL",
        "colab_type": "text"
      },
      "source": [
        "In Machine Learning an **attribute** is a data type (e.g., “Mileage”), while a **feature** has several meanings depending on the context, but generally means an attribute plus its value (e.g., “Mileage = 15,000”). Many people use the words attribute and feature interchangeably, though."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ur3iDOqRCsfN",
        "colab_type": "text"
      },
      "source": [
        "**Types of Regression Algorithms:-**\n",
        "\n",
        "There are many Regression algorithms are present in machine learning, which \n",
        "will use for different regression applications. Some of the main regression \n",
        "algorithms are as follows-\n",
        "\n",
        "**1.1.1. Simple Linear Regression:-**\n",
        "\n",
        "In simple linear regression, we predict scores on one variable from the ratings \n",
        "on a second variable. The variable we are forecasting is called the criterion \n",
        "variable and referred to as Y. The variable we are basing our predictions on is \n",
        "called the predictor variable and denoted to as X.\n",
        "\n",
        "\n",
        "\n",
        "**1.1.2. Multiple Linear Regression:-**\n",
        "\n",
        "Multiple linear regression is one of the algorithms of regression technique, and it is the most common form of linear regression analysis. As a predictive \n",
        "analysis, the multiple linear regression is used to explain the relationship \n",
        "between one dependent variable with two or more than two independent \n",
        "variables. The independent variables can be continuous or categorical.\n",
        "\n",
        "\n",
        "**1.1.3. Polynomial Regression:-**\n",
        "\n",
        "Polynomial regression is another form of regression in which the maximum \n",
        "power of the independent variable is more than 1. In this regression technique, \n",
        "the best fit line is not a straight line instead it is in the form of a curve.\n",
        "\n",
        "\n",
        "**1.1.4. Support Vector Regression:-**\n",
        "\n",
        "Support Vector Regression can be applied not only to regression problems, but \n",
        "it also used in the case of classification. It contains all the features that \n",
        "characterize maximum margin algorithm. Linear learning machine mapping \n",
        "leans a non-linear function into high dimensional kernel-induced feature space. \n",
        "The system capacity was controlled by parameters that do not depend on the \n",
        "dimensionality of feature space.\n",
        "\n",
        "\n",
        "\n",
        "**1.1.5. Ridge Regression:-**\n",
        "\n",
        "Ridge Regression is one of the algorithms used in Regression technique. It is a \n",
        "technique for analyzing multiple regression data that suffer from multicollinearity. By the addition of a degree of bias to the regression \n",
        "calculates, it reduces the standard errors. The net effect will be to give \n",
        "calculations that are more reliable.\n",
        "\n",
        "\n",
        "\n",
        "**1.1.6. Lasso Regression:-**\n",
        "\n",
        "Lasso regression is a type of linear regression that uses shrinkage. Shrinkage is where data values shrunk towards a central point, like the mean. The lasso \n",
        "procedure encourages simple, sparse models (i.e. models with fewer \n",
        "parameters). This particular type of regression is well-suited for models \n",
        "showing high levels of multicollinearity or when you want to automate certain \n",
        "parts of model selection, like variable selection/parameter elimination.\n",
        "\n",
        "\n",
        "**1.1.7. ElasticNet Regression:-**\n",
        "\n",
        "\n",
        "Elastic net regression combined L1 norms (LASSO) and L2 norms (ridge \n",
        "regression) into a penalized model for generalized linear regression, and it\n",
        "gives it sparsity (L1) and robustness (L2) properties.\n",
        "\n",
        "\n",
        "**1.1.8. Bayesian Regression:-**\n",
        "\n",
        "Bayesian regression allows a reasonably natural mechanism to survive \n",
        "insufficient data or poorly distributed data. It will enable you to put \n",
        "coefficients on the prior and the noise so that the priors can take over in the \n",
        "absence of data. More importantly, you can ask Bayesian regression which parts \n",
        "(if any) of its fit to the data are it confident about, and which parts are very uncertain.\n",
        "\n",
        "\n",
        "**1.1.9. Decision Tree Regression:-**\n",
        "\n",
        "Decision tree builds a form like a tree structure from regression models. It \n",
        "breaks down the data into smaller subsets and while an associated decision \n",
        "tree developed incrementally at the same time. The result is a tree with \n",
        "decision nodes and leaf nodes.\n",
        "\n",
        "\n",
        "**1.1.10. Random Forest Regression:-**\n",
        "\n",
        "Random Forest is also one of the algorithms used in regression technique, and \n",
        "it is very flexible, easy to use machine learning algorithm that produces, even \n",
        "without hyper-parameter tuning. Also, this algorithm widely used because of its \n",
        "simplicity and the fact that it can use for both regression and classification \n",
        "tasks. The forest it builds, is an ensemble of Decision Trees, most of the time \n",
        "trained with the “bagging” method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhLbHnaKf_LN",
        "colab_type": "text"
      },
      "source": [
        "**Classification**\n",
        "\n",
        "Classification is the type of Supervised Learning in which labelled data can use, and this data is used to make predictions in a non-continuous form. The output of the information is not always continuous, and the graph is non-linear. In the classification technique, the algorithm learns from the data input given to it and then uses this learning to classify new observation. This data set may merely be bi-class, or it may be multi-class too. Ex: - One of the examples of classification problems is to check whether the email is spam or not spam by train the algorithm for different spam words or emails.\n",
        "\n",
        "\n",
        "**1.2.1. Logistic Regression/Classification:-**\n",
        "\n",
        "Logistic regression falls under the category of supervised learning; it measures the relationship between the dependent variable which is categorical with one or more than one independent variables by estimating probabilities using a logistic/sigmoid function. Logistic regression can generally use where the dependent variable is Binary or Dichotomous. It means that the dependent \n",
        "variable can take only two possible values like “Yes or No”, “Living or Dead”.\n",
        "\n",
        "\n",
        "**1.2.2. K-Nearest Neighbors:-**\n",
        "\n",
        "KNN algorithm is one of the most straightforward algorithms in classification, \n",
        "and it is one of the most used learning algorithms. A majority vote of an object is classified by its neighbors, with the purpose being assigned to the class most common among its k nearest neighbors. It can also use for regression,output is the value of the object (predicts continuous values). This value is the average (or median) of the benefits of its k nearest neighbors.\n",
        "\n",
        "\n",
        "**1.2.3. Support Vector Machines:-**\n",
        "\n",
        "A Support Vector Machine is a type of Classifier, in which a discriminative \n",
        "classifier formally defined by a separating hyperplane. The algorithm outputs \n",
        "an optimal hyperplane which categorizes new examples. In two dimensional \n",
        "space, this hyperplane is a line dividing a plane into two parts wherein each \n",
        "class lay on either side.\n",
        "\n",
        "\n",
        "**1.2.4. Kernel Support Vector Machines:-**\n",
        "\n",
        "Kernel-SVM algorithm is one the algorithms used in classification technique, \n",
        "and it is mathematical functions set that defined as the kernel. The purpose of \n",
        "the core is to take data as input and transform it into the required form. \n",
        "Different SVM algorithms use different types of kernel functions. These \n",
        "functions can be different types. For example linear and nonlinear functions, \n",
        "polynomial functions, radial basis function, and sigmoid functions.\n",
        "\n",
        "\n",
        "**1.2.5. Naive Bayes:-**\n",
        "\n",
        "Naive Bayes is a type of Classification technique, which based on Bayes’ \n",
        "Theorem with an assumption of independence among predictors. In simple \n",
        "terms, a Naive Bayes classifier assumes that the presence of a particular \n",
        "feature in a class is unrelated to the presence of any other function. Naive \n",
        "Bayes model is accessible to build and particularly useful for extensive \n",
        "datasets.\n",
        "\n",
        "\n",
        "**1.2.6. Decision Tree Classification:-**\n",
        "\n",
        "Decision tree makes classification models in the form of a tree structure. An \n",
        "associated decision tree incrementally developed and at the same time it\n",
        "breaks down a large data-set into smaller subsets. The final result is a tree \n",
        "with decision nodes and leaf nodes. A decision node (e.g., Root) has two or \n",
        "more branches. Leaf node represents a classification or decision. The first \n",
        "decision node in a tree which corresponds to the best predictor called root \n",
        "node. Decision trees can handle both categorical and numerical data.\n",
        "\n",
        "\n",
        "**1.2.7. Random Forest Classification:-**\n",
        "\n",
        "Random Forest is a supervised learning algorithm. It creates a forest and makes \n",
        "it somehow casual. The wood it builds is an ensemble of Decision Trees, it most \n",
        "of the time the decision tree algorithm trained with the “bagging” method, \n",
        "which is a combination of learning models increases the overall result.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TatLowguCsfO",
        "colab_type": "text"
      },
      "source": [
        "## Unsupervised Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucPiN02CCsfQ",
        "colab_type": "text"
      },
      "source": [
        "Unsupervised learning is where you only have __input data (X)__ and __no corresponding output variables__.\n",
        "\n",
        "The __goal__ for unsupervised learning is to _model the underlying structure or distribution in the data in order to learn more about the data_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfX_iE5dk1Nx",
        "colab_type": "text"
      },
      "source": [
        "Unsupervised Learning is the second type of machine learning, in which \n",
        "unlabeled data are used to train the algorithm, which means it used against\n",
        "data that has no historical labels. What is being showing must figure out by the algorithm. The purpose is to explore the data and find some structure within. In unsupervised learning the data is unlabeled, and the input of raw \n",
        "information directly to the algorithm without pre-processing of the data and \n",
        "without knowing the output of the data and the data cannot divide into a train \n",
        "or test data. The algorithm figures out the data and according to the data \n",
        "segments, it makes clusters of data with new labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqi3OWnDlQB6",
        "colab_type": "text"
      },
      "source": [
        "This learning technique works well on transactional data. For example, it can \n",
        "identify segments of customers with similar attributes who can then be treated \n",
        "similarly in marketing campaigns. Or it can find the primary qualities that \n",
        "separate customer segments from each other. These algorithms are also used \n",
        "to segment text topics, recommend items and identify data outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL0629UsCsfS",
        "colab_type": "text"
      },
      "source": [
        "### Unsupervised learning problems can be further grouped into clustering and association problems.\n",
        "\n",
        "#### Clustering:\n",
        "A __clustering problem__ is where you want to discover the __inherent groupings__ in the data, such as _grouping customers by purchasing behavior_.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGSWPj9glzau",
        "colab_type": "text"
      },
      "source": [
        "Clustering is the type of Unsupervised Learning in which unlabeled data used, \n",
        "and it is the process of grouping similar entities together, and then the grouped data is used to make clusters. The goal of this unsupervised machine learning technique is to find similarities in the data point and group similar data points together and to figures out that new data should belong to which cluster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWS0So_l5w_x",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/AnkitNigam1985/Data-Science/master/tmp_images/tmp4.PNG\" width=\"600\" height=\"350\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVZm83i2no_y",
        "colab_type": "text"
      },
      "source": [
        "**2.1.1. K-Means Clustering:-**\n",
        "\n",
        "K-Means clustering is one of the algorithms of Clustering technique, in which \n",
        "similar data grouped in a cluster. K-means is an iterative clustering algorithm \n",
        "that aims to find local maxima in each iteration. It starts with K as the input \n",
        "which is how many groups you want to see. Input k centroids in random\n",
        "locations in your space. Now, with the use of the Euclidean distance method \n",
        "calculate the distance between data points and centroids, and assign data \n",
        "point to the cluster which is close to it. Recalculate the cluster centers as a \n",
        "mean of data points attached to it. Repeat until no further changes occur.\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/AnkitNigam1985/Data-Science/master/tmp_images/tmp6.PNG\" width=\"450\" height=\"450\" />\n",
        "\n",
        "\n",
        "**2.1.2. Hierarchical Clustering:-**\n",
        "\n",
        "Hierarchical clustering is one of the algorithms of Clustering technique, in \n",
        "which similar data grouped in a cluster. It is an algorithm that builds the \n",
        "hierarchy of clusters. This algorithm starts with all the data points assigned to a bunch of their own. Then two nearest groups are merged into the same \n",
        "cluster. In the end, this algorithm terminates when there is only a single \n",
        "cluster left. Start by assign each data point to its bunch. Now find the closest pair of the group using Euclidean distance and merge them into the single cluster. Then calculate the distance between two nearest clusters and combine until all items clustered into a single cluster.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx7sGkNW6MHD",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/AnkitNigam1985/Data-Science/master/tmp_images/tmp7.PNG\" width=\"450\" height=\"450\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_bSq9AflgS_",
        "colab_type": "text"
      },
      "source": [
        "#### Association:\n",
        "An __association rule__ learning problem is where you want to discover __rules that describe large portions__ of your data, such as _people that buy X also tend to buy Y_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2krDC0fzo1vn",
        "colab_type": "text"
      },
      "source": [
        "**2.2. Dimensionality Reduction:-**\n",
        "\n",
        "Dimensionality Reduction is the type of Unsupervised Learning, in which the \n",
        "dimensions of the data is reduced to remove the unwanted data from the \n",
        "input. This technique is used to remove the undesirable features of the data. It relates to the process of converting a set of data having large dimensions into data with carries same data and small sizes. These techniques used while \n",
        "solving machine learning problems to obtain better features.\n",
        "\n",
        "\n",
        "**2.2.1. Principal Component Analysis:-**\n",
        "\n",
        "Principal Component Analysis is one of the algorithms of Dimensionality \n",
        "Reduction, in this technique, it transformed into a new set of variables from \n",
        "old variables, which are the linear combination of real variables. Specific new \n",
        "set of variables are known as principal components. As a result of the \n",
        "transformation, the first primary component has the most significant possible \n",
        "variance, and each following element has the highest potential difference \n",
        "under the constraint that it is orthogonal to the above ingredients. Keeping \n",
        "only the first m < n components reduces the data dimensionality while \n",
        "retaining most of the data information.\n",
        "\n",
        "\n",
        "**2.2.2. Linear Discriminant Analysis:-**\n",
        "\n",
        "The linear discriminant analysis is one of the algorithms of Dimensionality \n",
        "Reduction in which it also creates linear combinations of your original features. However, unlike PCA, LDA doesn’t maximize explained variance. Instead, it optimizes the reparability between classes. LDA can improve the predictive \n",
        "performance of the extracted features. Furthermore, LDA offers variations to \n",
        "tackle specific roadblocks.\n",
        "\n",
        "\n",
        "**2.2.3. Kernel Principal Component Analysis:-**\n",
        "\n",
        "Kernel Principal Component Analysis is one of the algorithms of Dimensionality \n",
        "Reduction, and the variables which are transformed into variables of the new \n",
        "set, which are the non-linear combination of original variables means the \n",
        "nonlinear version of PCA, called as Kernel Principal Component Analysis (KPCA). \n",
        "It is capable of capturing part of the high order statistics, thus provides more information from the original dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-QCmjL9CsfU",
        "colab_type": "text"
      },
      "source": [
        "## Semisupervised learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6A26205CsfY",
        "colab_type": "text"
      },
      "source": [
        "Some algorithms can deal with __partially labeled training data__, usually a _lot of unlabeled data and a little bit of labeled data_. \n",
        "\n",
        "Some __photo-hosting services__, such as _Google Photos_, are good examples of this.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5Lz8t1qCsfa",
        "colab_type": "text"
      },
      "source": [
        "# Why Use Machine Learning?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAgJDPafCsfh",
        "colab_type": "text"
      },
      "source": [
        "###  To summarize, Machine Learning is great for:\n",
        "- Problems for which __existing solutions require a lot of hand-tuning__ or long lists of rules: one Machine Learning algorithm can often simplify code and perform better.\n",
        "\n",
        "- Complex problems for which __there is no good solution at all using a traditional approach__: the best Machine Learning techniques can find a solution.\n",
        "- __Fluctuating environments__: a Machine Learning system can adapt to new data.\n",
        "- Getting __insights__ about _complex problems_ and _large amounts of data_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wURXj4v7Csfj",
        "colab_type": "text"
      },
      "source": [
        "# Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30wHDkORCsfk",
        "colab_type": "text"
      },
      "source": [
        "Reinforcement Learning is a very different __beast__. The learning system, called an __agent__ in this context, can observe the __environment__, select and __perform actions__, and __get rewards__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1_XrZA5Csfo",
        "colab_type": "text"
      },
      "source": [
        "# Batch and Online Learning\n",
        "\n",
        "Another criterion used to classify Machine Learning systems is whether or not the system can __learn incrementally__ from a __stream of incoming data__.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eJJixHnCsfq",
        "colab_type": "text"
      },
      "source": [
        "## Batch learning\n",
        "\n",
        "In batch learning, the system is __incapable__ of learning incrementally: it must be _trained using all the available data_. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHLxgnWNCsfr",
        "colab_type": "text"
      },
      "source": [
        "## Online learning\n",
        "\n",
        "In online learning, you __train the system incrementally__ by feeding it data instances sequentially, either individually or by small groups called mini-batches. Each learning step is __fast and cheap__, so the system can learn about _new data on the fly_, as it arrives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qqpf3RFCsft",
        "colab_type": "text"
      },
      "source": [
        "# Instance-Based Versus Model-Based Learning\n",
        "\n",
        "One more way to categorize Machine Learning systems is by __how they generalize__."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16NBNLSQCsfu",
        "colab_type": "text"
      },
      "source": [
        "## Instance-based learning\n",
        "\n",
        "The system learns the examples by __heart__, then generalizes to new cases using a _similarity measure_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86hryhVxCsfw",
        "colab_type": "text"
      },
      "source": [
        "##  Model-based learning\n",
        "\n",
        "Another way to generalize from a __set of examples__ is to _build a model of these examples_, then use that model to make __predictions__. This is called model-based learning "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqOKSytnCsf7",
        "colab_type": "text"
      },
      "source": [
        "## The Machine Learning Stack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBAuq1PfCsf9",
        "colab_type": "text"
      },
      "source": [
        "# Technologies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zj6oJHhCsgA",
        "colab_type": "text"
      },
      "source": [
        "## R \n",
        "R is an integrated suite of software facilities for __data manipulation__, __calculation__ and __graphical display__. [4]\n",
        "## R-Studio\n",
        "RStudio is an __open source__ and enterprise-ready professional software for R. [5]\n",
        "## Python\n",
        "Python is a general-purpose interpreted, __dynamically typed__, __interactive__, __object-oriented__, and __high-level programming language__. [6]\n",
        "There are two main versions of python in use currently, __Python 2__ and __Python 3__.\n",
        "## Anaconda\n",
        "Anaconda is a __freemium open source distribution__ of the Python and R programming languages. [7]\n",
        "It is used for large-scale __data processing__, __predictive analytics__, and __scientific computing__, that aims to simplify package management and deployment. \n",
        "\n",
        "Its package management system is conda.\n",
        "## PyCharm \n",
        "PyCharm is an Integrated Development Environment (__IDE__) used in computer programming, specifically for the Python language.[8]\n",
        "\n",
        "PyCharm is cross-platform, with Windows, macOS and Linux versions.\n",
        "## Atom \n",
        "Atom is a __free and open-source__, __text__ and __source code editor__. [9]\n",
        "Available for macOS, Linux, and Microsoft Windows with support for plug-ins written in __Node.js__, and __embedded Git Control__, developed by GitHub. \n",
        "## Shell Script\n",
        "The shell is a program that takes your commands from the keyboard and gives them to the operating system to perform \n",
        "\n",
        "Shell is an environment in which we can run our __commands__, __programs__, and __shell scripts__.\n",
        "## Command Line\n",
        "It is a means of interacting with a computer program where client communicates with a system through __text based commands__\n",
        "## PuTTy\n",
        "PuTTY is a client program for the __SSH__, __Telnet__ and __Rlogin network__ protocols. These protocols are all used to run a __remote session__ on a computer, __over a network__. [10]\n",
        "## Dask\n",
        "Dask is a flexible __parallel computing library__ for analytic computing. [11]\n",
        "## TensorFlow\n",
        "TensorFlow™ is an open source software library for __numerical computation using data flow graphs__. [12]\n",
        "## PyTorch \n",
        "PyTorch is a python package that provides two high-level features: [13]\n",
        "\n",
        "1. __Tensor computation__ (like numpy) with strong _GPU acceleration_\n",
        "2. Deep Neural Networks built on a __tape-based autograd system__\n",
        "\n",
        "## Apache Spark \n",
        "Apache Spark is an open-source __cluster-computing__ framework. [14]\n",
        "## H2O\n",
        "It is a fast __statistical__, __machine learning__ & __math runtime__ for bigdata. [15]\n",
        "## DL4J\n",
        "Open-Source, Distributed, __Deep Learning Library__ for the JVM [16]\n",
        "## IBM Watson\n",
        "Watson is a __question answering__ computer system capable of answering questions posed in natural language, developed by IBM. [17]\n",
        "## Cassandra\n",
        "Apache Cassandra is a free and open-source distributed __NoSQL database management system__. [18]\n",
        "It is designed to handle large amounts of data across many __commodity servers__, providing high availability with __no__ _single point of failure_. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xx-KeLeDCsgB",
        "colab_type": "text"
      },
      "source": [
        "# Use Cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "acyhH9MuCsga",
        "colab_type": "text"
      },
      "source": [
        "### References\n",
        "[1] Frank Chamaki blog <br>\n",
        "[2] Victor Lavrenko<br>\n",
        "[3] Venturisity Blog<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COeKmgT0AiQt",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/AnkitNigam1985/Data-Science/master/tmp_images/20191225_130540.jpg\" width=\"500\" height=\"500\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFcpjZzeDix1",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/AnkitNigam1985/Data-Science/master/tmp_images/ML_basics_1.PNG\" width=\"500\" height=\"500\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK4bzVUsDuEy",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/AnkitNigam1985/Data-Science/master/tmp_images/ML_basics_2.PNG\" width=\"800\" height=\"600\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7UJ-QFQL4yh",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/AnkitNigam1985/Data-Science/master/tmp_images/ML_life_cycle.PNG\" width=\"800\" height=\"600\" />\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/AnkitNigam1985/Data-Science/master/tmp_images/ML-1_basics_Lavi_3.PNG\" width=\"800\" height=\"600\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La4n3-7FMvTj",
        "colab_type": "text"
      },
      "source": [
        "While analyzing data provided by the customer, the goals og customer and yours could vary but dependent on each other.\n",
        "Customer have bigger goals that we call Gloabl goal while the data scinece team to analyze the data to accomplish one or multiple local goals to achieve the global goal.\n",
        "So data scientist need to visualize multiple local goals based on the global goal provided by the customer\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/AnkitNigam1985/Data-Science/master/tmp_images/Global_goal_Local_Goal_Lavi_class_ML1.PNG\" width=\"800\" height=\"600\" />\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PczNpNJTNzLv",
        "colab_type": "text"
      },
      "source": [
        "**CLASS NOTES**\n",
        "\n",
        "**Day1**\n",
        "\n",
        "E,T, P -  Experience, Task, Performance\n",
        "\n",
        "O,G, M - observation, goal and measure\n",
        "\n",
        "Input -> features\n",
        "\n",
        "Output -> target\n",
        "\n",
        "ML maps data to the desired target\n",
        "\n",
        "categorical,countable - classification\n",
        "\n",
        "definite value - regression\n",
        "\n",
        "Classification is less error prone than regression\n",
        "\n",
        "\n",
        "Uber/Ola predicts the fare price uses regression\n",
        "\n",
        "Not all data is in tabular format or csv format, so we need to convert them into one, this is data engineering.\n",
        "\n",
        "For ML, we need to convert unstrucutred data into tabular format.\n",
        "\n",
        "Every data can have 2 sections - input(or features) and output(or target).\n",
        "\n",
        "\n",
        "Example of data science in real life-\n",
        "\n",
        "Getting average amount while contribution for team party\n",
        "\n",
        "Average salary in Market for specific skills\n",
        "\n",
        "When outcome is numerical, predicting continuos value - regression\n",
        "\n",
        "When outcome is category - numerical discrete or ordinal or nonimal - classification\n",
        "\n",
        "Few example tasks-\n",
        "\n",
        "Predicting stock prices - Regression\n",
        "\n",
        "Will the stock go up or down - classification\n",
        "\n",
        "issue loan or not - Classification\n",
        "\n",
        "How much loan can be issued - regression\n",
        "\n",
        "detecting cancer cells - Classfication\n",
        "\n",
        "Counting number of cells or area/size of cell - regression\n",
        "\n",
        "Stage/severity of cancer cells - classification\n",
        "\n",
        "\n",
        "Classification is more accurate than regression , as in regression we need to detect particular value while classification need to provide classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXMS7BuWUpVQ",
        "colab_type": "text"
      },
      "source": [
        "**Day2**\n",
        "\n",
        "Unstructured data like image can be converted into pixel values in tabular format before analysis\n",
        "\n",
        "JSON format needs to be converted into tabular format before analysis\n",
        "\n",
        "1. Most important is to get the correct data format for analysis\n",
        "\n",
        "2. GLoabl goal - main objective the compoany is looking\n",
        "\n",
        "Local goal - the objective that can be solved by ML\n",
        "\n",
        "Companies will know the global problems.\n",
        "\n",
        "Data Scientist need to think for local problems leading to global goals\n",
        "\n",
        "Range is classification\n",
        "\n",
        "For crime in Gurgaon\n",
        "E - number of crimes, locality, age groupes of victims and accused, type of crime, weapons\n",
        "\n",
        "T- crime happened or not\n",
        "\n",
        "Global goal is to reduce crime\n",
        "\n",
        "Local goal(or Task) - predict crime\n",
        "\n",
        "Our objective is to study the local goal\n",
        "\n",
        "\n",
        "Further examples of local and globa goal\n",
        "\n",
        "Global goal - Gross product buying should increase\n",
        "\n",
        "Local goal - Make prediction of recommendation of products that customer buys\n",
        " - classification\n",
        "\n",
        "Global goal - Loss of bank optimization\n",
        "\n",
        "Local goal - predict fraud - classification\n",
        "\n",
        "amount of fraud - regression\n",
        "\n",
        "risk associated with fraud - regression/classification\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Gloabl goal - Customer satisfication\n",
        "\n",
        "Local goal - good recommendation, good offers(regression)\n",
        "\n",
        "\n",
        "Global goal - Increase productivity of employees\n",
        "\n",
        "Local goal - Automatic filling in time sheet(class), prediction of appraisals(reg)\n",
        "\n",
        "\n",
        "GLoabl goal - Transposrt is seamless experience for people\n",
        "\n",
        "Local goal - Fares are predicted(reg), faster routes(optimization), surcharge dynamically caclulated(reg), alternative routes, ratings (regression)\n",
        "\n",
        "\n",
        "\n",
        "EDA is important to analyze data prior applying ML on it , if data is garbage, then prediction would be garbage\n",
        "\n",
        "From E(experience)-T(task)-P(performance),\n",
        "\n",
        "if T then supervised learning\n",
        "\n",
        "When no T but still need to find some pattern - then it is unsupervised learning\n",
        "\n",
        "\n",
        "Classiifcation is supervised \n",
        "\n",
        "Clustering is unsupervised\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zvd_L-DaxB-",
        "colab_type": "text"
      },
      "source": [
        "**Day3**\n",
        "\n",
        "\n",
        "When we have bank data, we apply unsupervised ML to get the clusters and then present it to business, business validate the clusters then we analyze the new data based on the given clusters, so this is supervised now as we know clusters.\n",
        "\n",
        "\n",
        "We divide the data into X_train,Y_train and X_test and Y_test\n",
        "\n",
        "\n",
        "Model training - Because this is supervised, we will divide the data into 2 parts. Train will have x as input and Y as predefined output. \n",
        "Once the model is built then we will check the performance of this data on the test data. \n",
        "Model Testing - We take the test data (X_test) and then apply the model to it. This gives the output as Y_test.\n",
        "Once the output is there, we will compare this Y_Test (Y_Predicted)  with Y_actual.\n",
        "\n",
        "\n",
        "we feed input as x train , y train .... then model is trained and we have x test and y test ..... we get some result and we compare it with y test .... it will tell accuracy\n",
        "\n",
        "\n",
        "Experience is -> X data Task is -> Y values and prediction success rate is -> performance\n",
        "\n",
        "\n",
        "Segmenting data based on known rules is filtering\n",
        "\n",
        "Segmenting data without any rules known is clustering/grouping\n",
        "\n",
        "Data Wranglig - remove noise from data, removing unexceptable format\n",
        "\n",
        "Data Mungging - Data can be easily accessed by model, data can be easily accessed by the model, example dummies data for string columns or one-hot encoding.\n",
        "\n",
        "Data Munging and Data wrangling are part of data pre-processing.\n",
        "\n",
        "Featutre selection - keeping only required columns and removing unnecessary columns, that would reduce the noise and also since columns decreased so effeciency would be better.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHjvl2lSbC3W",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/AnkitNigam1985/Data-Science/master/tmp_images/ML-1_basics_Lavi.PNG\" width=\"800\" height=\"600\" />\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/AnkitNigam1985/Data-Science/master/tmp_images/tmp5.PNG\" width=\"800\" height=\"600\" />\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/AnkitNigam1985/Data-Science/master/tmp_images/tmp8.PNG\" width=\"800\" height=\"600\" />\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/AnkitNigam1985/Data-Science/master/tmp_images/tmp9.PNG\" width=\"800\" height=\"600\" />\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/AnkitNigam1985/Data-Science/master/tmp_images/tmp10.PNG\" width=\"800\" height=\"600\" />\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/AnkitNigam1985/Data-Science/master/tmp_images/tmp11.PNG\" width=\"800\" height=\"600\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKIcoNWTnYve",
        "colab_type": "text"
      },
      "source": [
        "**QUIZ QUESTIONS**\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/AnkitNigam1985/Data-Science/master/tmp_images/tmp12.PNG\" width=\"800\" height=\"600\" />\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/AnkitNigam1985/Data-Science/master/tmp_images/tmp13.PNG\" width=\"800\" height=\"600\" />\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/AnkitNigam1985/Data-Science/master/tmp_images/tmp14.PNG\" width=\"800\" height=\"600\" />\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/AnkitNigam1985/Data-Science/master/tmp_images/tmp15.PNG\" width=\"500\" height=\"500\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHQujJupnxfQ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}